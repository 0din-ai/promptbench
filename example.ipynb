{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example will walk you throught the basic usage of PromptBench. We hope that you can get familiar with the APIs and use it in your own projects later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, there is a unified import of `import promptbench as pb` that easily imports the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptbench as pb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "First, PromptBench supports easy load of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cola', 'sst2', 'qqp', 'mnli', 'mnli_matched', 'mnli_mismatched', 'qnli', 'wnli', 'rte', 'mrpc', 'mmlu', 'squad_v2', 'un_multi', 'iwslt', 'math', 'bool_logic', 'valid_parentheses']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': \"it 's a charming and often affecting journey . \", 'label': 1},\n",
       " {'content': 'unflinchingly bleak and desperate ', 'label': 0},\n",
       " {'content': 'allows us to hope that nolan is poised to embark a major career as a commercial yet inventive filmmaker . ',\n",
       "  'label': 1},\n",
       " {'content': \"the acting , costumes , music , cinematography and sound are all astounding given the production 's austere locales . \",\n",
       "  'label': 1},\n",
       " {'content': \"it 's slow -- very , very slow . \", 'label': 0}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all supported datasets in promptbench\n",
    "print(pb.DatasetLoader.dataset_list())\n",
    "\n",
    "# load a dataset, sst2, for instance.\n",
    "# if the dataset is not available locally, it will be downloaded automatically.\n",
    "dataset = pb.DatasetLoader.load_dataset(\"sst2\")\n",
    "\n",
    "# print the first 5 examples\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'t5': ['google/flan-t5-large'], 'llama': ['llama2-7b', 'llama2-7b-chat', 'llama2-13b', 'llama2-13b-chat', 'llama2-70b', 'llama2-70b-chat'], 'gpt': ['gpt-3.5-turbo', 'gpt-4'], 'vicuna': ['vicuna-7b', 'vicuna-13b', 'vicuna-13b-v1.3'], 'ul2': ['google/flan-ul2']}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /media/Zeus/haoc/miniconda/envs/promptbench/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda116.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 116\n",
      "CUDA SETUP: Loading binary /media/Zeus/haoc/miniconda/envs/promptbench/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda116.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/Zeus/haoc/miniconda/envs/promptbench/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /media/Zeus/haoc/miniconda/envs/promptbench did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/media/Zeus/haoc/miniconda/envs/promptbench/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/media/Zeus/haoc/miniconda/envs/promptbench/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('\"/home/haoc/.vscode-server/data/clp/9f233b0c8bdef919c90298683f3dac6b.zh-cn\",\"_resolvedLanguagePackCoreLocation\"'), PosixPath('\"zh-cn\"},\"_languagePackId\"'), PosixPath('\"/home/haoc/.vscode-server/data/clp/9f233b0c8bdef919c90298683f3dac6b.zh-cn/tcf.json\",\"_cacheRoot\"'), PosixPath('\"9f233b0c8bdef919c90298683f3dac6b.zh-cn\",\"_translationsConfigFile\"'), PosixPath('\"/home/haoc/.vscode-server/data/clp/9f233b0c8bdef919c90298683f3dac6b.zh-cn/f1b07bd25dfad64b0167beb15359ae573aecd2cc\",\"_corruptedFile\"'), PosixPath('\"/home/haoc/.vscode-server/data/clp/9f233b0c8bdef919c90298683f3dac6b.zh-cn/corrupted.info\",\"_languagePackSupport\"'), PosixPath('\"zh-cn\",\"osLocale\"'), PosixPath('\"zh-cn\",\"availableLanguages\"'), PosixPath('{\"*\"'), PosixPath('{\"locale\"'), PosixPath('true}')}\n",
      "  warn(msg)\n",
      "/media/Zeus/haoc/miniconda/envs/promptbench/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/Users/triste/.vscode/extensions/ms-ceintl.vscode-language-pack-zh-hans-1.83.2023101109/translations/extensions/vscode.markdown-language-features.i18n.json'), PosixPath('vscode-local')}\n",
      "  warn(msg)\n",
      "/media/Zeus/haoc/miniconda/envs/promptbench/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/media/Zeus/haoc/miniconda/envs/promptbench/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0'), PosixPath('/usr/local/cuda/lib64/libcudart.so')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "2023-10-30 02:12:42.719470: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "print(pb.LLMModel.model_list())\n",
    "model = pb.LLMModel(model='google/flan-t5-large', max_new_tokens=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = pb.Prompt([\"Classify the sentence as positive or negative: {content}\",\n",
    "                     \"Determine the emotion of the following sentence as positive or negative: {content}\"\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "You may need to define the projection function for the model output.\n",
    "Since the output format defined in your prompts may be different from the model output.\n",
    "For example, for sst2 dataset, the label are '0' and '1' to represent 'negative' and 'positive'.\n",
    "But the model output is 'negative' and 'positive'.\n",
    "So we need to define a projection function to map the model output to the label.\n",
    "\"\"\"\n",
    "def proj_func(pred):\n",
    "    mapping = {\n",
    "        \"positive\": 1,\n",
    "        \"negative\": 0\n",
    "    }\n",
    "    return mapping.get(pred, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [02:16<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947, Classify the sentence as positive or negative: {content}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [02:18<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.947, Determine the emotion of the following sentence as positive or negative: {content}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for prompt in prompts:\n",
    "    preds = []\n",
    "    labels = []\n",
    "    for data in tqdm(dataset):\n",
    "        # process input\n",
    "        input_text = pb.InputProcess.basic_format(prompt, data)\n",
    "        label = data['label']\n",
    "\n",
    "        raw_pred = model(input_text)\n",
    "        # process output\n",
    "        pred = pb.OutputProcess.cls(raw_pred, proj_func)\n",
    "        preds.append(pred)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # evaluate\n",
    "    score = pb.Eval.compute_cls_accuracy(preds, labels)\n",
    "    print(f\"{score:.3f}, {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "promptbench",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
